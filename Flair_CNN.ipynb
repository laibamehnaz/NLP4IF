{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. class Dataloader  ( From FLAIR )\n",
    "#### For some reason it can't be imported using  : from flair.datasets import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data.dataloader\n",
    "from torch.utils.data.dataset import Subset, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataLoader(torch.utils.data.dataloader.DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        sampler=None,\n",
    "        batch_sampler=None,\n",
    "        num_workers=8,\n",
    "        drop_last=False,\n",
    "        timeout=0,\n",
    "        worker_init_fn=None,\n",
    "    ):\n",
    "\n",
    "        # in certain cases, multi-CPU data loading makes no sense and slows\n",
    "        # everything down. For this reason, we detect if a dataset is in-memory:\n",
    "        # if so, num_workers is set to 0 for faster processing\n",
    "        flair_dataset = dataset\n",
    "        while True:\n",
    "            if type(flair_dataset) is Subset:\n",
    "                flair_dataset = flair_dataset.dataset\n",
    "            elif type(flair_dataset) is ConcatDataset:\n",
    "                flair_dataset = flair_dataset.datasets[0]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if type(flair_dataset) is list:\n",
    "            num_workers = 0\n",
    "        elif isinstance(flair_dataset, FlairDataset) and flair_dataset.is_in_memory():\n",
    "            num_workers = 0\n",
    "\n",
    "        super(DataLoader, self).__init__(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            sampler=sampler,\n",
    "            batch_sampler=batch_sampler,\n",
    "            num_workers=num_workers,\n",
    "            collate_fn=list,\n",
    "            drop_last=drop_last,\n",
    "            timeout=timeout,\n",
    "            worker_init_fn=worker_init_fn,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Loading the datasets and preprocessing it for FLAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/.../train-train.csv' )\n",
    "\n",
    "df_train_flair = df_train[\"Class\"]\n",
    "df_train_flair = df_train_flair.to_frame()\n",
    "df_train_flair[\"Sentence\"] = df_train[\"Sentence\"]\n",
    "\n",
    "df_train_flair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/.../train-dev.csv' )\n",
    "\n",
    "df_test_flair = df_test[\"Class\"]\n",
    "df_test_flair = df_test_flair.to_frame()\n",
    "df_test_flair[\"Sentence\"] = df_test[\"Sentence\"]\n",
    "df_test_flair = df_test_flair[:50]\n",
    "df_test_flair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_flair['Class'] = '__label__' + df_train_flair['Class'].astype(str)\n",
    "df_test_flair['Class'] = '__label__' + df_test_flair['Class'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_flair.to_csv('/.../train.csv', sep='\\t', index = False, header = False)\n",
    "df_test_flair.to_csv('/.../test.csv', sep='\\t', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('/content/drive/My Drive/Offenseval_Datasets/folder/'), test_file='test.csv', train_file = 'train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. This is the module embedding.py \n",
    "##### Class edited : class DocumentLSTMEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "from abc import abstractmethod\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import List, Union, Dict\n",
    "import gensim\n",
    "import numpy as np\n",
    "import torch\n",
    "from bpemb import BPEmb\n",
    "from deprecated import deprecated\n",
    "\n",
    "from pytorch_pretrained_bert import (\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    TransfoXLTokenizer,\n",
    "    TransfoXLModel,\n",
    "    OpenAIGPTModel,\n",
    "    OpenAIGPTTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.modeling_openai import (\n",
    "    PRETRAINED_MODEL_ARCHIVE_MAP as OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP,\n",
    ")\n",
    "\n",
    "from pytorch_pretrained_bert.modeling_transfo_xl import (\n",
    "    PRETRAINED_MODEL_ARCHIVE_MAP as TRANSFORMER_XL_PRETRAINED_MODEL_ARCHIVE_MAP,\n",
    ")\n",
    "\n",
    "import flair\n",
    "from flair.data import Corpus\n",
    "from flair.data import Sentence, Corpus, Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Embeddings(torch.nn.Module):\n",
    "    \"\"\"Abstract base class for all embeddings. Every new type of embedding must implement these methods.\"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def embedding_length(self) -> int:\n",
    "        \"\"\"Returns the length of the embedding vector.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def embedding_type(self) -> str:\n",
    "        pass\n",
    "\n",
    "    def embed(self, sentences: Union[Sentence, List[Sentence]]) -> List[Sentence]:\n",
    "        \"\"\"Add embeddings to all words in a list of sentences. If embeddings are already added, updates only if embeddings\n",
    "        are non-static.\"\"\"\n",
    "\n",
    "        # if only one sentence is passed, convert to list of sentence\n",
    "        if type(sentences) is Sentence:\n",
    "            sentences = [sentences]\n",
    "\n",
    "        everything_embedded: bool = True\n",
    "\n",
    "        if self.embedding_type == \"word-level\":\n",
    "            for sentence in sentences:\n",
    "                for token in sentence.tokens:\n",
    "                    if self.name not in token._embeddings.keys():\n",
    "                        everything_embedded = False\n",
    "        else:\n",
    "            for sentence in sentences:\n",
    "                if self.name not in sentence._embeddings.keys():\n",
    "                    everything_embedded = False\n",
    "\n",
    "        if not everything_embedded or not self.static_embeddings:\n",
    "            self._add_embeddings_internal(sentences)\n",
    "\n",
    "        return sentences\n",
    "\n",
    "    @abstractmethod\n",
    "    def _add_embeddings_internal(self, sentences: List[Sentence]) -> List[Sentence]:\n",
    "        \"\"\"Private method for adding embeddings to all words in a list of sentences.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "class TokenEmbeddings(Embeddings):\n",
    "    \"\"\"Abstract base class for all token-level embeddings. Ever new type of word embedding must implement these methods.\"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def embedding_length(self) -> int:\n",
    "        \"\"\"Returns the length of the embedding vector.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def embedding_type(self) -> str:\n",
    "        return \"word-level\"\n",
    "\n",
    "\n",
    "class StackedEmbeddings(TokenEmbeddings):\n",
    "    \"\"\"A stack of embeddings, used if you need to combine several different embedding types.\"\"\"\n",
    "\n",
    "    def __init__(self, embeddings: List[TokenEmbeddings], detach: bool = True):\n",
    "        \"\"\"The constructor takes a list of embeddings to be combined.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings = embeddings\n",
    "\n",
    "        # IMPORTANT: add embeddings as torch modules\n",
    "        for i, embedding in enumerate(embeddings):\n",
    "            self.add_module(\"list_embedding_{}\".format(i), embedding)\n",
    "\n",
    "        self.detach: bool = detach\n",
    "        self.name: str = \"Stack\"\n",
    "        self.static_embeddings: bool = True\n",
    "\n",
    "        self.__embedding_type: str = embeddings[0].embedding_type\n",
    "          \n",
    "        self.__embedding_length: int = 0\n",
    "        for embedding in embeddings:\n",
    "            self.__embedding_length += embedding.embedding_length\n",
    "            \n",
    "        \n",
    "    def embed(\n",
    "        self, sentences: Union[Sentence, List[Sentence]], static_embeddings: bool = True\n",
    "    ):\n",
    "        # if only one sentence is passed, convert to list of sentence\n",
    "        if type(sentences) is Sentence:\n",
    "            sentences = [sentences]\n",
    "\n",
    "        for embedding in self.embeddings:\n",
    "            embedding.embed(sentences)\n",
    "\n",
    "    @property\n",
    "    def embedding_type(self) -> str:\n",
    "        return self.__embedding_type\n",
    "\n",
    "    @property\n",
    "    def embedding_length(self) -> int:\n",
    "        return self.__embedding_length\n",
    "\n",
    "    def _add_embeddings_internal(self, sentences: List[Sentence]) -> List[Sentence]:\n",
    "\n",
    "        for embedding in self.embeddings:\n",
    "            embedding._add_embeddings_internal(sentences)\n",
    "\n",
    "        return sentences\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'StackedEmbeddings [{\",\".join([str(e) for e in self.embeddings])}]'\n",
    "\n",
    "      \n",
    "\n",
    "class DocumentEmbeddings(Embeddings):\n",
    "    \"\"\"Abstract base class for all document-level embeddings. Ever new type of document embedding must implement these methods.\"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def embedding_length(self) -> int:\n",
    "        \"\"\"Returns the length of the embedding vector.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def embedding_type(self) -> str:\n",
    "        return \"sentence-level\"      \n",
    "      \n",
    "class DocumentLSTMEmbeddings(DocumentEmbeddings):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings: List[TokenEmbeddings],\n",
    "        hidden_size=128,\n",
    "        rnn_layers=1,\n",
    "        reproject_words: bool = True,\n",
    "        reproject_words_dimension: int = None,\n",
    "        bidirectional: bool = True,\n",
    "        dropout: float = 0.5,\n",
    "        word_dropout: float = 0.0,\n",
    "        locked_dropout: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"The constructor takes a list of embeddings to be combined.\n",
    "        :param embeddings: a list of token embeddings\n",
    "        :param hidden_size: the number of hidden states in the lstm\n",
    "        :param rnn_layers: the number of layers for the lstm\n",
    "        :param reproject_words: boolean value, indicating whether to reproject the token embeddings in a separate linear\n",
    "        layer before putting them into the lstm or not\n",
    "        :param reproject_words_dimension: output dimension of reprojecting token embeddings. If None the same output\n",
    "        dimension as before will be taken.\n",
    "        :param bidirectional: boolean value, indicating whether to use a bidirectional lstm or not\n",
    "        :param dropout: the dropout value to be used\n",
    "        :param word_dropout: the word dropout value to be used, if 0.0 word dropout is not used\n",
    "        :param locked_dropout: the locked dropout value to be used, if 0.0 locked dropout is not used\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings: StackedEmbeddings = StackedEmbeddings( embeddings = embeddings )\n",
    "\n",
    "        self.reproject_words = reproject_words\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.length_of_all_token_embeddings: int = self.embeddings.embedding_length\n",
    "\n",
    "        self.name = \"document_lstm\"\n",
    "        self.static_embeddings = False\n",
    "\n",
    "        self.__embedding_length: int = hidden_size\n",
    "        if self.bidirectional:\n",
    "            self.__embedding_length *= 4\n",
    "\n",
    "        self.embeddings_dimension: int = self.length_of_all_token_embeddings\n",
    "    \n",
    "        if self.reproject_words and reproject_words_dimension is not None:\n",
    "            self.embeddings_dimension = reproject_words_dimension\n",
    "\n",
    "        # bidirectional LSTM on top of embedding layer\n",
    "        self.word_reprojection_map = torch.nn.Linear(\n",
    "            self.length_of_all_token_embeddings, self.embeddings_dimension\n",
    "        )\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            self.embeddings_dimension,\n",
    "            hidden_size,\n",
    "            num_layers=rnn_layers,\n",
    "            bidirectional=self.bidirectional,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # dropouts\n",
    "        if locked_dropout > 0.0:\n",
    "            self.dropout: torch.nn.Module = LockedDropout(locked_dropout)\n",
    "        else:\n",
    "            self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.use_word_dropout: bool = word_dropout > 0.0\n",
    "        if self.use_word_dropout:\n",
    "            self.word_dropout = WordDropout(word_dropout)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.word_reprojection_map.weight)\n",
    "\n",
    "        self.to(flair.device)\n",
    "\n",
    "    @property\n",
    "    def embedding_length(self) -> int:\n",
    "        return self.__embedding_length\n",
    "\n",
    "    def embed(self, sentences: Union[List[Sentence], Sentence]):\n",
    "        \"\"\"Add embeddings to all sentences in the given list of sentences. If embeddings are already added, update\n",
    "         only if embeddings are non-static.\"\"\"\n",
    "\n",
    "        if type(sentences) is Sentence:\n",
    "            sentences = [sentences]\n",
    "\n",
    "        self.rnn.zero_grad()\n",
    "\n",
    "        sentences.sort(key=lambda x: len(x), reverse=True)\n",
    "\n",
    "        self.embeddings.embed(sentences)\n",
    "\n",
    "        # first, sort sentences by number of tokens\n",
    "        longest_token_sequence_in_batch: int = len(sentences[0])\n",
    "      \n",
    "        all_sentence_tensors = []\n",
    "        lengths: List[int] = []\n",
    "\n",
    "        # go through each sentence in batch\n",
    "        for i, sentence in enumerate(sentences):\n",
    "\n",
    "            lengths.append(len(sentence.tokens))\n",
    "\n",
    "            word_embeddings = []\n",
    "\n",
    "            for token, token_idx in zip(sentence.tokens, range(len(sentence.tokens))):\n",
    "                word_embeddings.append(token.get_embedding().unsqueeze(0))\n",
    "            \n",
    "        \n",
    "            # PADDING: pad shorter sentences out\n",
    "            for add in range(longest_token_sequence_in_batch - len(sentence.tokens)):\n",
    "                word_embeddings.append(\n",
    "                    torch.zeros(\n",
    "                        self.length_of_all_token_embeddings, dtype=torch.float\n",
    "                    ).unsqueeze(0)\n",
    "                )\n",
    "        \n",
    "            word_embeddings_tensor = torch.cat(word_embeddings, 0).to(flair.device)\n",
    "           \n",
    "\n",
    "            sentence_states = word_embeddings_tensor\n",
    "\n",
    "            \"\"\"\n",
    "            1. The normal function is to send the word embeddings for the entire batch through a linear layer and then LSTM and\n",
    "               then further take the representations from there for each sentence. The dimension of the word embedding tensor for \n",
    "               each sentence was [( hidden_size )]. This would  make the input for the CNN layer only a 2d vector. \n",
    "            \n",
    "            2.Right now the sentence has an embedding_tensor of the shape [( max_sentence_len , embedding_length )]\n",
    "            \n",
    "            3.The same word embedding tensor has been attached each sentence so that the input to the CNN layer cna be a \n",
    "              3d vector.\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            ### ADDING IT TO THE SENTENCE DIRECTLY\n",
    "            \n",
    "            sentence.set_embedding(self.name, word_embeddings_tensor)\n",
    "            \n",
    "            print(\"SIZE OF THE EMBEDDING ADDED TO THE CURRENT SENTENCE IS : \")\n",
    "            print( word_embeddings_tensor.size() )\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            # ADD TO SENTENCE LIST: add the representation\n",
    "            all_sentence_tensors.append(sentence_states.unsqueeze(1))\n",
    "            #all_sentence_tensors.append(sentence_states)\n",
    "            \n",
    "            print(\"6 . All_sentence_tensors just one element  : \")\n",
    "            print(all_sentence_tensors[0].size())\n",
    "            #print(all_sentence_tensors[0])\n",
    "            \"\"\"\n",
    "\n",
    "            \n",
    "        \"\"\"    \n",
    "        # --------------------------------------------------------------------\n",
    "        # GET REPRESENTATION FOR ENTIRE BATCH\n",
    "        # --------------------------------------------------------------------\n",
    "        \n",
    "        print(\"THE REPRESENTATION OF THE ENTIRE BATCH : \")\n",
    "        print()\n",
    "        sentence_tensor = torch.cat(all_sentence_tensors, 1)\n",
    "        print()\n",
    "        print(sentence_tensor.size())\n",
    "        print()\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        # FF PART\n",
    "        # --------------------------------------------------------------------\n",
    "        # use word dropout if set\n",
    "        if self.use_word_dropout:\n",
    "            sentence_tensor = self.word_dropout(sentence_tensor)\n",
    "\n",
    "        if self.reproject_words:\n",
    "            sentence_tensor = self.word_reprojection_map(sentence_tensor)\n",
    "            \n",
    "        print(\"8 . AFTER REPROJECT_WORDS : \")\n",
    "        print(sentence_tensor.size())\n",
    "\n",
    "        sentence_tensor = self.dropout(sentence_tensor)\n",
    "\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(sentence_tensor, lengths)\n",
    "       \n",
    "\n",
    "        self.rnn.flatten_parameters()\n",
    "\n",
    "        lstm_out, hidden = self.rnn(packed)\n",
    "\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm_out)\n",
    "        print(\"OUTPUTS :\")\n",
    "        print(outputs.size())\n",
    "        print()\n",
    "        print(\"8 . AFTER RNN_PAD_PACKED : OUTPUTS \")\n",
    "        print( outputs.size() )\n",
    "        \n",
    "        print(\"8.1 OUTPUTS AFTER SQUEEZE() : \")\n",
    "        print( outputs.squeeze(1).size() )\n",
    "        print(outputs.squeeze(1))\n",
    "\n",
    "        outputs = self.dropout(outputs)\n",
    "        \n",
    "        print()\n",
    "        print(\"9 . AFTER DROPOUT : OUTPUTS \")\n",
    "        print( outputs.size() )\n",
    "\n",
    "        print(\"***length***\")\n",
    "        print(lengths)\n",
    "        # --------------------------------------------------------------------\n",
    "        # EXTRACT EMBEDDINGS FROM LSTM\n",
    "        # --------------------------------------------------------------------\n",
    "        \n",
    "        for sentence_no, length in enumerate(lengths):\n",
    "            print(\" 9. sentence_no :\")\n",
    "            print(sentence_no)\n",
    "            print()\n",
    "            print(\" 9. length :\")\n",
    "            print(length)\n",
    "            print()\n",
    "            \n",
    "            #last_rep = outputs[length - 1, sentence_no]\n",
    "            #print(\"LAST_REP : \")\n",
    "            #print(last_rep.size())\n",
    "            #print(last_rep)\n",
    "            \n",
    "            embedding = outputs.squeeze(1)\n",
    "            #if self.bidirectional:\n",
    "                #first_rep = outputs[0, sentence_no]\n",
    "                #print(\"FIRST_REP : \")\n",
    "                #print(first_rep.size())\n",
    "                #embedding = torch.cat([first_rep, last_rep], 0)\n",
    "                #print(\"CONCAT FIRST AND LAST_REP :\")\n",
    "                #print(embedding.size())\n",
    "            print(\"EMBEDDING BEING ATTACHED TO THE SENTENCE : \")\n",
    "            print(embedding.size())\n",
    "            sentence = sentences[sentence_no]\n",
    "            sentence.set_embedding(self.name, outputs.squeeze(1))\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    def _add_embeddings_internal(self, sentences: List[Sentence]):\n",
    "        pass\n",
    "\n",
    "\n",
    "      \n",
    "      \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Creating embeddings for our corpus : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
    "flair_backward_embedding = FlairEmbeddings('multi-backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embeddings = [ flair_forward_embedding ,  flair_backward_embedding  ]\n",
    "\n",
    "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, \n",
    "reproject_words = False , reproject_words_dimension=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. class Textclassifier ( changes have been made in _init_() and forward() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flair.data import Dictionary, Sentence, Label\n",
    "from flair.file_utils import cached_path\n",
    "from flair.training_utils import (\n",
    "    convert_labels_to_one_hot,\n",
    "    clear_embeddings,\n",
    "    Metric,\n",
    "    Result,\n",
    ")\n",
    "\n",
    "from typing import List, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextClassifier(flair.nn.Model):\n",
    "    \"\"\"\n",
    "    Text Classification Model\n",
    "    The model takes word embeddings, puts them into an RNN to obtain a text representation, and puts the\n",
    "    text representation in the end into a linear layer to get the actual class label.\n",
    "    The model can handle single and multi class data sets.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_train , \n",
    "        document_embeddings: flair.embeddings.DocumentEmbeddings,\n",
    "        label_dictionary: Dictionary,\n",
    "        multi_label: bool = None,\n",
    "        multi_label_threshold: float = 0.5,\n",
    "        \n",
    "    ):\n",
    "\n",
    "        super(TextClassifier, self).__init__()\n",
    "\n",
    "        \n",
    "        \n",
    "        self.document_embeddings: flair.embeddings.DocumentRNNEmbeddings = document_embeddings\n",
    "        self.label_dictionary: Dictionary = label_dictionary\n",
    "        kernel_size = [ 5 , 6 ]\n",
    "            \n",
    "        \"\"\" \n",
    "        Calculating the maximum_length_of_the_sentence\n",
    "        \"\"\"\n",
    "        \n",
    "        train_dev_sentences_for_prediction = self.test_to_sentences(  df_train_flair )\n",
    "        train_dev_sentences_for_prediction.sort(key=lambda x: len(x), reverse=True)\n",
    "        longest_token_sequence_in_batch: int = len(train_dev_sentences_for_prediction[0])\n",
    "        self.max_sen_len = longest_token_sequence_in_batch\n",
    "         \n",
    "        if multi_label is not None:\n",
    "            self.multi_label = multi_label\n",
    "        else:\n",
    "            self.multi_label = self.label_dictionary.multi_label\n",
    "\n",
    "        self.multi_label_threshold = multi_label_threshold\n",
    "\n",
    "        \"\"\"\n",
    "        The CNN layer : \n",
    "        in_channel : embedding_length\n",
    "        \n",
    "        As of now self.document_embeddings.embedding_length does not give the actual embedding_size of the final \n",
    "        embedding_tensor. Will try out something to accomadate this.  \n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d( in_channels = 4096 , out_channels = 100 , kernel_size = kernel_size[0] ) ,      \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(self.max_sen_len - kernel_size[0] + 1)\n",
    "        )\n",
    "        \n",
    "    \n",
    "        # self.decoder = nn.Linear( num_channels * len( kernel_size ) , len(self.label_dictionary() ))    \n",
    "        self.decoder = nn.Linear( 1 * 100 , len(self.label_dictionary)\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "        if self.multi_label:\n",
    "            self.loss_function = nn.BCEWithLogitsLoss()\n",
    "        else:\n",
    "            self.loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "        # auto-spawn on GPU if available\n",
    "        self.to(flair.device)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def test_to_sentences( self, df_test_flair ):\n",
    "        train_dev_sents_list = [  x for x in df_test_flair['Sentence'] ]\n",
    "        print(\"Sentences list created : \")\n",
    "        train_dev_sentences_for_prediction = []\n",
    "\n",
    "        for i in train_dev_sents_list : \n",
    "            train_dev_sentences_for_prediction.append(Sentence(i))\n",
    "    \n",
    "        return train_dev_sentences_for_prediction    \n",
    "    \n",
    "    \n",
    "    def _init_weights(self):\n",
    "        ##initialising weights for the linear layer\n",
    "        nn.init.xavier_uniform_(self.decoder.weight)\n",
    "     \n",
    "        \n",
    "   \n",
    "    def _get_state_dict(self):\n",
    "        print(\"Model's state_dict:\")\n",
    "        \n",
    "        \"\"\"\n",
    "        To check each layer of the model\n",
    "        \"\"\"\n",
    "        for param_tensor in self.state_dict():\n",
    "            print(param_tensor, \"\\t\", self.state_dict()[param_tensor].size())\n",
    "       \n",
    "    \n",
    "        model_state = {\n",
    "            \"state_dict\": self.state_dict(),\n",
    "            \"document_embeddings\": self.document_embeddings,\n",
    "            \"label_dictionary\": self.label_dictionary,\n",
    "            \"multi_label\": self.multi_label,\n",
    "        }\n",
    "        return model_state    \n",
    "    \n",
    "    def forward(self, sentences) -> List[List[float]]:\n",
    "        \n",
    "        self.document_embeddings.embed(sentences)\n",
    "\n",
    "        text_embedding_list = [\n",
    "            sentence.get_embedding().unsqueeze(0) for sentence in sentences\n",
    "        ]\n",
    "       \n",
    "        text_embedding_tensor = torch.cat(text_embedding_list, 0).to(flair.device)\n",
    "        \n",
    "        embedded_sent = text_embedding_tensor.permute(0,2,1)\n",
    "        # embedded_sent.size() = ( batch_size ,  embedding_size , max_sentence_length )    \n",
    "    \n",
    "        conv_out1 = self.conv1( embedded_sent ).squeeze(2)\n",
    "        label_scores = self.decoder( conv_out1 )\n",
    "\n",
    "        return label_scores\n",
    "\n",
    "      \n",
    "    def _init_model_with_state_dict(state):\n",
    "\n",
    "        model = TextClassifier(\n",
    "            document_embeddings=state[\"document_embeddings\"],\n",
    "            label_dictionary=state[\"label_dictionary\"],\n",
    "            multi_label=state[\"multi_label\"],\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(state[\"state_dict\"])\n",
    "        return model\n",
    "\n",
    "    def forward_loss(self, sentences: Union[List[Sentence], Sentence]) -> torch.tensor:\n",
    "        scores = self.forward(sentences)\n",
    "        return self._calculate_loss(scores, sentences)\n",
    "\n",
    "    def forward_labels_and_loss(\n",
    "        self, sentences: Union[Sentence, List[Sentence]]\n",
    "    ) -> (List[List[Label]], torch.tensor):\n",
    "        scores = self.forward(sentences)\n",
    "        labels = self._obtain_labels(scores)\n",
    "        loss = self._calculate_loss(scores, sentences)\n",
    "        return labels, loss\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        sentences: Union[Sentence, List[Sentence]],\n",
    "        mini_batch_size: int = 32,\n",
    "        multi_class_prob: bool = False,\n",
    "    ) -> List[Sentence]:\n",
    "        \"\"\"\n",
    "        Predicts the class labels for the given sentences. The labels are directly added to the sentences.\n",
    "        :param sentences: list of sentences\n",
    "        :param mini_batch_size: mini batch size to use\n",
    "        :param multi_class_prob : return probability for all class for multiclass\n",
    "        :return: the list of sentences containing the labels\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            if type(sentences) is Sentence:\n",
    "                sentences = [sentences]\n",
    "\n",
    "            filtered_sentences = self._filter_empty_sentences(sentences)\n",
    "\n",
    "            batches = [\n",
    "                filtered_sentences[x : x + mini_batch_size]\n",
    "                for x in range(0, len(filtered_sentences), mini_batch_size)\n",
    "            ]\n",
    "\n",
    "            for batch in batches:\n",
    "                scores = self.forward(batch)\n",
    "                predicted_labels = self._obtain_labels(\n",
    "                    scores, predict_prob=multi_class_prob\n",
    "                )\n",
    "\n",
    "                for (sentence, labels) in zip(batch, predicted_labels):\n",
    "                    sentence.labels = labels\n",
    "\n",
    "                clear_embeddings(batch)\n",
    "\n",
    "            return sentences\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        sentences: List[Sentence],\n",
    "        eval_mini_batch_size: int = 32,\n",
    "        embeddings_in_memory: bool = False,\n",
    "        out_path: Path = None,\n",
    "        num_workers: int = 8,\n",
    "    ) -> (Result, float):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            eval_loss = 0\n",
    "\n",
    "            batch_loader = DataLoader(\n",
    "                sentences,\n",
    "                batch_size=eval_mini_batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=num_workers,\n",
    "            )\n",
    "\n",
    "            metric = Metric(\"Evaluation\")\n",
    "\n",
    "            lines: List[str] = []\n",
    "            batch_count: int = 0\n",
    "            for batch in batch_loader:\n",
    "\n",
    "                batch_count += 1\n",
    "\n",
    "                labels, loss = self.forward_labels_and_loss(batch)\n",
    "\n",
    "                clear_embeddings(\n",
    "                    batch, also_clear_word_embeddings=not embeddings_in_memory\n",
    "                )\n",
    "\n",
    "                eval_loss += loss\n",
    "\n",
    "                sentences_for_batch = [sent.to_plain_string() for sent in batch]\n",
    "                confidences_for_batch = [\n",
    "                    [label.score for label in sent_labels] for sent_labels in labels\n",
    "                ]\n",
    "                predictions_for_batch = [\n",
    "                    [label.value for label in sent_labels] for sent_labels in labels\n",
    "                ]\n",
    "                true_values_for_batch = [\n",
    "                    sentence.get_label_names() for sentence in batch\n",
    "                ]\n",
    "                available_labels = self.label_dictionary.get_items()\n",
    "\n",
    "                for sentence, confidence, prediction, true_value in zip(\n",
    "                    sentences_for_batch,\n",
    "                    confidences_for_batch,\n",
    "                    predictions_for_batch,\n",
    "                    true_values_for_batch,\n",
    "                ):\n",
    "                    eval_line = \"{}\\t{}\\t{}\\t{}\\n\".format(\n",
    "                        sentence, true_value, prediction, confidence\n",
    "                    )\n",
    "                    lines.append(eval_line)\n",
    "\n",
    "                for predictions_for_sentence, true_values_for_sentence in zip(\n",
    "                    predictions_for_batch, true_values_for_batch\n",
    "                ):\n",
    "\n",
    "                    for label in available_labels:\n",
    "                        if (\n",
    "                            label in predictions_for_sentence\n",
    "                            and label in true_values_for_sentence\n",
    "                        ):\n",
    "                            metric.add_tp(label)\n",
    "                        elif (\n",
    "                            label in predictions_for_sentence\n",
    "                            and label not in true_values_for_sentence\n",
    "                        ):\n",
    "                            metric.add_fp(label)\n",
    "                        elif (\n",
    "                            label not in predictions_for_sentence\n",
    "                            and label in true_values_for_sentence\n",
    "                        ):\n",
    "                            metric.add_fn(label)\n",
    "                        elif (\n",
    "                            label not in predictions_for_sentence\n",
    "                            and label not in true_values_for_sentence\n",
    "                        ):\n",
    "                            metric.add_tn(label)\n",
    "\n",
    "            eval_loss /= batch_count\n",
    "\n",
    "            detailed_result = (\n",
    "                f\"\\nMICRO_AVG: acc {metric.micro_avg_accuracy()} - f1-score {metric.micro_avg_f_score()}\"\n",
    "                f\"\\nMACRO_AVG: acc {metric.macro_avg_accuracy()} - f1-score {metric.macro_avg_f_score()}\"\n",
    "            )\n",
    "            for class_name in metric.get_classes():\n",
    "                detailed_result += (\n",
    "                    f\"\\n{class_name:<10} tp: {metric.get_tp(class_name)} - fp: {metric.get_fp(class_name)} - \"\n",
    "                    f\"fn: {metric.get_fn(class_name)} - tn: {metric.get_tn(class_name)} - precision: \"\n",
    "                    f\"{metric.precision(class_name):.4f} - recall: {metric.recall(class_name):.4f} - \"\n",
    "                    f\"accuracy: {metric.accuracy(class_name):.4f} - f1-score: \"\n",
    "                    f\"{metric.f_score(class_name):.4f}\"\n",
    "                )\n",
    "\n",
    "            result = Result(\n",
    "                main_score=metric.micro_avg_f_score(),\n",
    "                log_line=f\"{metric.precision()}\\t{metric.recall()}\\t{metric.micro_avg_f_score()}\",\n",
    "                log_header=\"PRECISION\\tRECALL\\tF1\",\n",
    "                detailed_results=detailed_result,\n",
    "            )\n",
    "\n",
    "            if out_path is not None:\n",
    "                with open(out_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "                    outfile.write(\"\".join(lines))\n",
    "\n",
    "            return result, eval_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def _filter_empty_sentences(sentences: List[Sentence]) -> List[Sentence]:\n",
    "        filtered_sentences = [sentence for sentence in sentences if sentence.tokens]\n",
    "        if len(sentences) != len(filtered_sentences):\n",
    "            log.warning(\n",
    "                \"Ignore {} sentence(s) with no tokens.\".format(\n",
    "                    len(sentences) - len(filtered_sentences)\n",
    "                )\n",
    "            )\n",
    "        return filtered_sentences\n",
    "\n",
    "    def _calculate_loss(\n",
    "        self, scores: torch.tensor, sentences: List[Sentence]\n",
    "    ) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Calculates the loss.\n",
    "        :param scores: the prediction scores from the model\n",
    "        :param sentences: list of sentences\n",
    "        :return: loss value\n",
    "        \"\"\"\n",
    "        if self.multi_label:\n",
    "            return self._calculate_multi_label_loss(scores, sentences)\n",
    "\n",
    "        return self._calculate_single_label_loss(scores, sentences)\n",
    "\n",
    "    def _obtain_labels(\n",
    "        self, scores: List[List[float]], predict_prob: bool = False\n",
    "    ) -> List[List[Label]]:\n",
    "        \"\"\"\n",
    "        Predicts the labels of sentences.\n",
    "        :param scores: the prediction scores from the model\n",
    "        :return: list of predicted labels\n",
    "        \"\"\"\n",
    "\n",
    "        if self.multi_label:\n",
    "            return [self._get_multi_label(s) for s in scores]\n",
    "\n",
    "        elif predict_prob:\n",
    "            return [self._predict_label_prob(s) for s in scores]\n",
    "\n",
    "        return [self._get_single_label(s) for s in scores]\n",
    "\n",
    "    def _get_multi_label(self, label_scores) -> List[Label]:\n",
    "        labels = []\n",
    "\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        results = list(map(lambda x: sigmoid(x), label_scores))\n",
    "        for idx, conf in enumerate(results):\n",
    "            if conf > self.multi_label_threshold:\n",
    "                label = self.label_dictionary.get_item_for_index(idx)\n",
    "                labels.append(Label(label, conf.item()))\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def _get_single_label(self, label_scores) -> List[Label]:\n",
    "        softmax = torch.nn.functional.softmax(label_scores, dim=0)\n",
    "        conf, idx = torch.max(softmax, 0)\n",
    "        label = self.label_dictionary.get_item_for_index(idx.item())\n",
    "\n",
    "        return [Label(label, conf.item())]\n",
    "\n",
    "    def _predict_label_prob(self, label_scores) -> List[Label]:\n",
    "        softmax = torch.nn.functional.softmax(label_scores, dim=0)\n",
    "        label_probs = []\n",
    "        for idx, conf in enumerate(softmax):\n",
    "            label = self.label_dictionary.get_item_for_index(idx)\n",
    "            label_probs.append(Label(label, conf.item()))\n",
    "        return label_probs\n",
    "\n",
    "    def _calculate_multi_label_loss(\n",
    "        self, label_scores, sentences: List[Sentence]\n",
    "    ) -> float:\n",
    "        return self.loss_function(label_scores, self._labels_to_one_hot(sentences))\n",
    "\n",
    "    def _calculate_single_label_loss(\n",
    "        self, label_scores, sentences: List[Sentence]\n",
    "    ) -> float:\n",
    "        return self.loss_function(label_scores, self._labels_to_indices(sentences))\n",
    "\n",
    "    def _labels_to_one_hot(self, sentences: List[Sentence]):\n",
    "        label_list = [sentence.get_label_names() for sentence in sentences]\n",
    "        one_hot = convert_labels_to_one_hot(label_list, self.label_dictionary)\n",
    "        one_hot = [torch.FloatTensor(l).unsqueeze(0) for l in one_hot]\n",
    "        one_hot = torch.cat(one_hot, 0).to(flair.device)\n",
    "        return one_hot\n",
    "\n",
    "    def _labels_to_indices(self, sentences: List[Sentence]):\n",
    "        indices = [\n",
    "            torch.LongTensor(\n",
    "                [\n",
    "                    self.label_dictionary.get_idx_for_item(label.value)\n",
    "                    for label in sentence.labels\n",
    "                ]\n",
    "            )\n",
    "            for sentence in sentences\n",
    "        ]\n",
    "\n",
    "        vec = torch.cat(indices, 0).to(flair.device)\n",
    "\n",
    "        return vec\n",
    "\n",
    "    def _fetch_model(model_name) -> str:\n",
    "\n",
    "        model_map = {}\n",
    "        aws_resource_path = (\n",
    "            \"https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4\"\n",
    "        )\n",
    "\n",
    "        model_map[\"de-offensive-language\"] = \"/\".join(\n",
    "            [\n",
    "                aws_resource_path,\n",
    "                \"TEXT-CLASSIFICATION_germ-eval-2018_task-1\",\n",
    "                \"germ-eval-2018-task-1.pt\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        model_map[\"en-sentiment\"] = \"/\".join(\n",
    "            [aws_resource_path, \"TEXT-CLASSIFICATION_imdb\", \"imdb.pt\"]\n",
    "        )\n",
    "\n",
    "        cache_dir = Path(\"models\")\n",
    "        if model_name in model_map:\n",
    "            model_name = cached_path(model_map[model_name], cache_dir=cache_dir)\n",
    "\n",
    "        return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = TextClassifier( df_train_flair , document_embeddings, \n",
    "label_dictionary = corpus.make_label_dictionary(), multi_label = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Training \n",
    "#### class ModelTrainer() : \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "import datetime\n",
    "\n",
    "from torch.optim.sgd import SGD\n",
    "from torch.utils.data.dataset import ConcatDataset\n",
    "\n",
    "import flair\n",
    "import flair.nn\n",
    "from flair.data import Sentence, MultiCorpus, Corpus\n",
    "#from flair.datasets import DataLoader\n",
    "\n",
    "from flair.training_utils import (\n",
    "    init_output_file,\n",
    "    WeightExtractor,\n",
    "    clear_embeddings,\n",
    "    EvaluationMetric,\n",
    "    log_line,\n",
    "    add_file_handler,\n",
    "    Result,\n",
    ")\n",
    "from flair.optim import *\n",
    "\n",
    "log = logging.getLogger(\"flair\")\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: flair.nn.Model,\n",
    "        corpus: Corpus,\n",
    "        optimizer: Optimizer = SGD,\n",
    "        epoch: int = 0,\n",
    "        loss: float = 10000.0,\n",
    "        optimizer_state: dict = None,\n",
    "        scheduler_state: dict = None,\n",
    "    ):\n",
    "        self.model: flair.nn.Model = model\n",
    "        self.corpus: Corpus = corpus\n",
    "        self.optimizer: Optimizer = optimizer\n",
    "        self.epoch: int = epoch\n",
    "        self.loss: float = loss\n",
    "        self.scheduler_state: dict = scheduler_state\n",
    "        self.optimizer_state: dict = optimizer_state\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        base_path: Union[Path, str],\n",
    "        evaluation_metric: EvaluationMetric = EvaluationMetric.MICRO_F1_SCORE,\n",
    "        learning_rate: float = 0.1,\n",
    "        mini_batch_size: int = 32,\n",
    "        eval_mini_batch_size: int = None,\n",
    "        max_epochs: int = 100,\n",
    "        anneal_factor: float = 0.5,\n",
    "        patience: int = 3,\n",
    "        train_with_dev: bool = False,\n",
    "        monitor_train: bool = False,\n",
    "        monitor_test: bool = False,\n",
    "        embeddings_in_memory: bool = True,\n",
    "        checkpoint: bool = False,\n",
    "        save_final_model: bool = True,\n",
    "        anneal_with_restarts: bool = False,\n",
    "        shuffle: bool = True,\n",
    "        param_selection_mode: bool = False,\n",
    "        num_workers: int = 8,\n",
    "        sampler=None,\n",
    "        **kwargs,\n",
    "    ) -> dict:\n",
    "\n",
    "        if eval_mini_batch_size is None:\n",
    "            eval_mini_batch_size = mini_batch_size\n",
    "\n",
    "        # cast string to Path\n",
    "        if type(base_path) is str:\n",
    "            base_path = Path(base_path)\n",
    "\n",
    "        log_handler = add_file_handler(log, base_path / \"training.log\")\n",
    "\n",
    "        log_line(log)\n",
    "        log.info(f'Model: \"{self.model}\"')\n",
    "        log_line(log)\n",
    "        log.info(f'Corpus: \"{self.corpus}\"')\n",
    "        log_line(log)\n",
    "        log.info(\"Parameters:\")\n",
    "        log.info(f' - learning_rate: \"{learning_rate}\"')\n",
    "        log.info(f' - mini_batch_size: \"{mini_batch_size}\"')\n",
    "        log.info(f' - patience: \"{patience}\"')\n",
    "        log.info(f' - anneal_factor: \"{anneal_factor}\"')\n",
    "        log.info(f' - max_epochs: \"{max_epochs}\"')\n",
    "        log.info(f' - shuffle: \"{shuffle}\"')\n",
    "        log.info(f' - train_with_dev: \"{train_with_dev}\"')\n",
    "        log_line(log)\n",
    "        log.info(f'Model training base path: \"{base_path}\"')\n",
    "        log_line(log)\n",
    "        log.info(f\"Evaluation method: {evaluation_metric.name}\")\n",
    "\n",
    "        # determine what splits (train, dev, test) to evaluate and log\n",
    "        log_train = True if monitor_train else False\n",
    "        log_test = (\n",
    "            True\n",
    "            if (not param_selection_mode and self.corpus.test and monitor_test)\n",
    "            else False\n",
    "        )\n",
    "        log_dev = True if not train_with_dev else False\n",
    "\n",
    "        # prepare loss logging file and set up header\n",
    "        loss_txt = init_output_file(base_path, \"loss.tsv\")\n",
    "\n",
    "        weight_extractor = WeightExtractor(base_path)\n",
    "\n",
    "        optimizer = self.optimizer(self.model.parameters(), lr=learning_rate, **kwargs)\n",
    "        if self.optimizer_state is not None:\n",
    "            optimizer.load_state_dict(self.optimizer_state)\n",
    "\n",
    "        # minimize training loss if training with dev data, else maximize dev score\n",
    "        anneal_mode = \"min\" if train_with_dev else \"max\"\n",
    "\n",
    "        if isinstance(optimizer, (AdamW, SGDW)):\n",
    "            scheduler = ReduceLRWDOnPlateau(\n",
    "                optimizer,\n",
    "                factor=anneal_factor,\n",
    "                patience=patience,\n",
    "                mode=anneal_mode,\n",
    "                verbose=True,\n",
    "            )\n",
    "        else:\n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                factor=anneal_factor,\n",
    "                patience=patience,\n",
    "                mode=anneal_mode,\n",
    "                verbose=True,\n",
    "            )\n",
    "        if self.scheduler_state is not None:\n",
    "            scheduler.load_state_dict(self.scheduler_state)\n",
    "\n",
    "        train_data = self.corpus.train\n",
    "\n",
    "        # if training also uses dev data, include in training set\n",
    "        if train_with_dev:\n",
    "            train_data = ConcatDataset([self.corpus.train, self.corpus.dev])\n",
    "\n",
    "        if sampler is not None:\n",
    "            sampler = sampler(train_data)\n",
    "\n",
    "        dev_score_history = []\n",
    "        dev_loss_history = []\n",
    "        train_loss_history = []\n",
    "        \n",
    "       \n",
    "\n",
    "        # At any point you can hit Ctrl + C to break out of training early.\n",
    "        try:\n",
    "            previous_learning_rate = learning_rate\n",
    "\n",
    "            for epoch in range(0 + self.epoch, max_epochs + self.epoch):\n",
    "                log_line(log)\n",
    "\n",
    "                # get new learning rate\n",
    "                for group in optimizer.param_groups:\n",
    "                    learning_rate = group[\"lr\"]\n",
    "\n",
    "                # reload last best model if annealing with restarts is enabled\n",
    "                if (\n",
    "                    learning_rate != previous_learning_rate\n",
    "                    and anneal_with_restarts\n",
    "                    and (base_path / \"best-model.pt\").exists()\n",
    "                ):\n",
    "                    log.info(\"resetting to best model\")\n",
    "                    self.model.load(base_path / \"best-model.pt\")\n",
    "\n",
    "                previous_learning_rate = learning_rate\n",
    "\n",
    "                # stop training if learning rate becomes too small\n",
    "                if learning_rate < 0.0001:\n",
    "                    log_line(log)\n",
    "                    log.info(\"learning rate too small - quitting training!\")\n",
    "                    log_line(log)\n",
    "                    break\n",
    "\n",
    "                batch_loader = DataLoader(\n",
    "                    train_data,\n",
    "                    batch_size=mini_batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    num_workers=num_workers,\n",
    "                    sampler=sampler,\n",
    "                )\n",
    "\n",
    "                self.model.train()\n",
    "\n",
    "                train_loss: float = 0\n",
    "\n",
    "                seen_batches = 0\n",
    "                total_number_of_batches = len(batch_loader)\n",
    "                \n",
    "                modulo = max(1, int(total_number_of_batches / 10))\n",
    "\n",
    "                # process mini-batches\n",
    "                for batch_no, batch in enumerate(batch_loader):\n",
    "                    \n",
    "                    loss = self.model.forward_loss(batch)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 5.0)\n",
    "                    optimizer.step()\n",
    "\n",
    "                    seen_batches += 1\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                    clear_embeddings(\n",
    "                        batch, also_clear_word_embeddings=not embeddings_in_memory\n",
    "                    )\n",
    "\n",
    "                    if batch_no % modulo == 0:\n",
    "                        log.info(\n",
    "                            f\"epoch {epoch + 1} - iter {batch_no}/{total_number_of_batches} - loss \"\n",
    "                            f\"{train_loss / seen_batches:.8f}\"\n",
    "                        )\n",
    "                        iteration = epoch * total_number_of_batches + batch_no\n",
    "                        if not param_selection_mode:\n",
    "                            weight_extractor.extract_weights(\n",
    "                                self.model.state_dict(), iteration\n",
    "                            )\n",
    "\n",
    "                train_loss /= seen_batches\n",
    "\n",
    "                self.model.eval()\n",
    "\n",
    "                log_line(log)\n",
    "                log.info(\n",
    "                    f\"EPOCH {epoch + 1} done: loss {train_loss:.4f} - lr {learning_rate:.4f}\"\n",
    "                )\n",
    "\n",
    "                # anneal against train loss if training with dev, otherwise anneal against dev score\n",
    "                current_score = train_loss\n",
    "\n",
    "                # evaluate on train / dev / test split depending on training settings\n",
    "                result_line: str = \"\"\n",
    "\n",
    "                if log_train:\n",
    "                    train_eval_result, train_loss = self.model.evaluate(\n",
    "                        self.corpus.train,\n",
    "                        eval_mini_batch_size,\n",
    "                        embeddings_in_memory,\n",
    "                        num_workers=num_workers,\n",
    "                    )\n",
    "                    result_line += f\"\\t{train_eval_result.log_line}\"\n",
    "\n",
    "                if log_dev:\n",
    "                    dev_eval_result, dev_loss = self.model.evaluate(\n",
    "                        self.corpus.dev,\n",
    "                        eval_mini_batch_size,\n",
    "                        embeddings_in_memory,\n",
    "                        num_workers=num_workers,\n",
    "                    )\n",
    "                    result_line += f\"\\t{dev_loss}\\t{dev_eval_result.log_line}\"\n",
    "                    log.info(\n",
    "                        f\"DEV : loss {dev_loss} - score {dev_eval_result.main_score}\"\n",
    "                    )\n",
    "                    # calculate scores using dev data if available\n",
    "                    # append dev score to score history\n",
    "                    dev_score_history.append(dev_eval_result.main_score)\n",
    "                    dev_loss_history.append(dev_loss)\n",
    "\n",
    "                    current_score = dev_eval_result.main_score\n",
    "\n",
    "                if log_test:\n",
    "                    test_eval_result, test_loss = self.model.evaluate(\n",
    "                        self.corpus.test,\n",
    "                        eval_mini_batch_size,\n",
    "                        embeddings_in_memory,\n",
    "                        base_path / \"test.tsv\",\n",
    "                        num_workers=num_workers,\n",
    "                    )\n",
    "                    result_line += f\"\\t{test_loss}\\t{test_eval_result.log_line}\"\n",
    "                    log.info(\n",
    "                        f\"TEST : loss {test_loss} - score {test_eval_result.main_score}\"\n",
    "                    )\n",
    "\n",
    "                # determine learning rate annealing through scheduler\n",
    "                scheduler.step(current_score)\n",
    "\n",
    "                train_loss_history.append(train_loss)\n",
    "\n",
    "                # determine bad epoch number\n",
    "                try:\n",
    "                    bad_epochs = scheduler.num_bad_epochs\n",
    "                except:\n",
    "                    bad_epochs = 0\n",
    "                for group in optimizer.param_groups:\n",
    "                    new_learning_rate = group[\"lr\"]\n",
    "                if new_learning_rate != previous_learning_rate:\n",
    "                    bad_epochs = patience + 1\n",
    "\n",
    "                # log bad epochs\n",
    "                log.info(f\"BAD EPOCHS (no improvement): {bad_epochs}\")\n",
    "\n",
    "                # output log file\n",
    "                with open(loss_txt, \"a\") as f:\n",
    "\n",
    "                    # make headers on first epoch\n",
    "                    if epoch == 0:\n",
    "                        f.write(\n",
    "                            f\"EPOCH\\tTIMESTAMP\\tBAD_EPOCHS\\tLEARNING_RATE\\tTRAIN_LOSS\"\n",
    "                        )\n",
    "\n",
    "                        if log_train:\n",
    "                            f.write(\n",
    "                                \"\\tTRAIN_\"\n",
    "                                + \"\\tTRAIN_\".join(\n",
    "                                    train_eval_result.log_header.split(\"\\t\")\n",
    "                                )\n",
    "                            )\n",
    "                        if log_dev:\n",
    "                            f.write(\n",
    "                                \"\\tDEV_LOSS\\tDEV_\"\n",
    "                                + \"\\tDEV_\".join(dev_eval_result.log_header.split(\"\\t\"))\n",
    "                            )\n",
    "                        if log_test:\n",
    "                            f.write(\n",
    "                                \"\\tTEST_LOSS\\tTEST_\"\n",
    "                                + \"\\tTEST_\".join(\n",
    "                                    test_eval_result.log_header.split(\"\\t\")\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "                    f.write(\n",
    "                        f\"\\n{epoch}\\t{datetime.datetime.now():%H:%M:%S}\\t{bad_epochs}\\t{learning_rate:.4f}\\t{train_loss}\"\n",
    "                    )\n",
    "                    f.write(result_line)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                \"\"\"\n",
    "                1. As of now it cannot save the best model so this has been commented. Since it cannot save the best model it\n",
    "                   will not work on the test set . To save the best model and retrieve it \n",
    "                   for testing on the test dataset , i will have to save the TextClassifier() seperately as and import it . \n",
    "                   Hopefully it should work then . \n",
    "                \n",
    "                \"\"\"    \n",
    "                    \n",
    "                \"\"\"     \n",
    "                # if checkpoint is enable, save model at each epoch\n",
    "                if checkpoint and not param_selection_mode:\n",
    "                    self.model.save_checkpoint(\n",
    "                        base_path / \"checkpoint.pt\",\n",
    "                        optimizer.state_dict(),\n",
    "                        scheduler.state_dict(),\n",
    "                        epoch + 1,\n",
    "                        train_loss,\n",
    "                    )\n",
    "\n",
    "                # if we use dev data, remember best model based on dev evaluation score\n",
    "                if (\n",
    "                    not train_with_dev\n",
    "                    and not param_selection_mode\n",
    "                    and current_score == scheduler.best\n",
    "                ):\n",
    "                    self.model.save(base_path / \"best-model.pt\")\n",
    "                 \"\"\"\n",
    "                \n",
    "            \"\"\"    \n",
    "            # if we do not use dev data for model selection, save final model\n",
    "            if save_final_model and not param_selection_mode:\n",
    "                self.model.save(base_path / \"final-model.pt\")\n",
    "            \"\"\"    \n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            log_line(log)\n",
    "            log.info(\"Exiting from training early.\")\n",
    "            if not param_selection_mode:\n",
    "                log.info(\"Saving model ...\")\n",
    "                self.model.save(base_path / \"final-model.pt\")\n",
    "                log.info(\"Done.\")\n",
    "\n",
    "        \"\"\"        \n",
    "        # test best model if test data is present\n",
    "        if self.corpus.test:\n",
    "            final_score = self.final_test(\n",
    "                base_path,\n",
    "                embeddings_in_memory,\n",
    "                evaluation_metric,\n",
    "                eval_mini_batch_size,\n",
    "                num_workers,\n",
    "            )\n",
    "        else:\n",
    "            final_score = 0\n",
    "            log.info(\"Test data not provided setting final score to 0\")\n",
    "\n",
    "        log.removeHandler(log_handler)\n",
    "\n",
    "        return {\n",
    "            \"test_score\": final_score,\n",
    "            \"dev_score_history\": dev_score_history,\n",
    "            \"train_loss_history\": train_loss_history,\n",
    "            \"dev_loss_history\": dev_loss_history,\n",
    "        }\n",
    "\n",
    "        \"\"\"\n",
    "    def final_test(\n",
    "        self,\n",
    "        base_path: Path,\n",
    "        embeddings_in_memory: bool,\n",
    "        evaluation_metric: EvaluationMetric,\n",
    "        eval_mini_batch_size: int,\n",
    "        num_workers: int = 8,\n",
    "    ):\n",
    "\n",
    "        log_line(log)\n",
    "        log.info(\"Testing using best model ...\")\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        if (base_path / \"best-model.pt\").exists():\n",
    "            self.model = self.model.load(base_path / \"best-model.pt\")\n",
    "\n",
    "        test_results, test_loss = self.model.evaluate(\n",
    "            self.corpus.test,\n",
    "            eval_mini_batch_size=eval_mini_batch_size,\n",
    "            embeddings_in_memory=embeddings_in_memory,\n",
    "            out_path=base_path / \"test.tsv\",\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "\n",
    "        test_results: Result = test_results\n",
    "        log.info(test_results.log_line)\n",
    "        log.info(test_results.detailed_results)\n",
    "        log_line(log)\n",
    "\n",
    "        # if we are training over multiple datasets, do evaluation for each\n",
    "        if type(self.corpus) is MultiCorpus:\n",
    "            for subcorpus in self.corpus.corpora:\n",
    "                log_line(log)\n",
    "                self.model.evaluate(\n",
    "                    subcorpus.test,\n",
    "                    eval_mini_batch_size,\n",
    "                    embeddings_in_memory,\n",
    "                    base_path / f\"{subcorpus.name}-test.tsv\",\n",
    "                )\n",
    "\n",
    "        # get and return the final test score of best model\n",
    "        final_score = test_results.main_score\n",
    "\n",
    "        return final_score\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_checkpoint(\n",
    "        cls, checkpoint, corpus: Corpus, optimizer: Optimizer = SGD\n",
    "    ):\n",
    "        return ModelTrainer(\n",
    "            checkpoint[\"model\"],\n",
    "            corpus,\n",
    "            optimizer,\n",
    "            epoch=checkpoint[\"epoch\"],\n",
    "            loss=checkpoint[\"loss\"],\n",
    "            optimizer_state=checkpoint[\"optimizer_state_dict\"],\n",
    "            scheduler_state=checkpoint[\"scheduler_state_dict\"],\n",
    "        )\n",
    "\n",
    "    def find_learning_rate(\n",
    "        self,\n",
    "        base_path: Union[Path, str],\n",
    "        file_name: str = \"learning_rate.tsv\",\n",
    "        start_learning_rate: float = 1e-7,\n",
    "        end_learning_rate: float = 10,\n",
    "        iterations: int = 100,\n",
    "        mini_batch_size: int = 32,\n",
    "        stop_early: bool = True,\n",
    "        smoothing_factor: float = 0.98,\n",
    "        **kwargs,\n",
    "    ) -> Path:\n",
    "        best_loss = None\n",
    "        moving_avg_loss = 0\n",
    "\n",
    "        # cast string to Path\n",
    "        if type(base_path) is str:\n",
    "            base_path = Path(base_path)\n",
    "        learning_rate_tsv = init_output_file(base_path, file_name)\n",
    "\n",
    "        with open(learning_rate_tsv, \"a\") as f:\n",
    "            f.write(\"ITERATION\\tTIMESTAMP\\tLEARNING_RATE\\tTRAIN_LOSS\\n\")\n",
    "\n",
    "        optimizer = self.optimizer(\n",
    "            self.model.parameters(), lr=start_learning_rate, **kwargs\n",
    "        )\n",
    "\n",
    "        train_data = self.corpus.train\n",
    "\n",
    "        batch_loader = DataLoader(train_data, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "        scheduler = ExpAnnealLR(optimizer, end_learning_rate, iterations)\n",
    "\n",
    "        model_state = self.model.state_dict()\n",
    "        model_device = next(self.model.parameters()).device\n",
    "        self.model.train()\n",
    "\n",
    "        for itr, batch in enumerate(batch_loader):\n",
    "            loss = self.model.forward_loss(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            learning_rate = scheduler.get_lr()[0]\n",
    "\n",
    "            loss_item = loss.item()\n",
    "            if itr == 0:\n",
    "                best_loss = loss_item\n",
    "            else:\n",
    "                if smoothing_factor > 0:\n",
    "                    moving_avg_loss = (\n",
    "                        smoothing_factor * moving_avg_loss\n",
    "                        + (1 - smoothing_factor) * loss_item\n",
    "                    )\n",
    "                    loss_item = moving_avg_loss / (1 - smoothing_factor ** (itr + 1))\n",
    "                if loss_item < best_loss:\n",
    "                    best_loss = loss\n",
    "\n",
    "            if stop_early and (loss_item > 4 * best_loss or torch.isnan(loss)):\n",
    "                log_line(log)\n",
    "                log.info(\"loss diverged - stopping early!\")\n",
    "                break\n",
    "\n",
    "            if itr > iterations:\n",
    "                break\n",
    "\n",
    "            with open(learning_rate_tsv, \"a\") as f:\n",
    "                f.write(\n",
    "                    f\"{itr}\\t{datetime.datetime.now():%H:%M:%S}\\t{learning_rate}\\t{loss_item}\\n\"\n",
    "                )\n",
    "\n",
    "        self.model.load_state_dict(model_state)\n",
    "        self.model.to(model_device)\n",
    "\n",
    "        log_line(log)\n",
    "        log.info(f\"learning rate finder finished - plot {learning_rate_tsv}\")\n",
    "        log_line(log)\n",
    "\n",
    "        return Path(learning_rate_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.train('./', max_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
